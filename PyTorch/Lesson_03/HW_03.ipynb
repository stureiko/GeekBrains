{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попрактикуемся с тем, что изучили\n",
    "\n",
    "Будем практиковаться на датасете:\n",
    "https://www.kaggle.com/c/avito-demand-prediction\n",
    "\n",
    "Ваша задача:\n",
    "1. Создать Dataset для загрузки данных (используем только числовые данные)\n",
    "2. Обернуть его в Dataloader\n",
    "3. Написать архитектуру сети, которая предсказывает число показов на основании числовых данных (вы всегда можете нагенерить дополнительных факторов). Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "4. Учить будем на функцию потерь с кагла (log RMSE) - нужно её реализовать\n",
    "5. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
    "\n",
    "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25\n",
    "\n",
    "Вопросы? в личку @Kinetikm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:25:26.689940Z",
     "start_time": "2022-02-09T07:25:15.870138Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:39:25.647398Z",
     "start_time": "2022-02-09T07:39:25.626102Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"class MyDataset \n",
    "    convert all categorical fields to numbers (categorical codes)\n",
    "    \"\"\"\n",
    "    def __init__(self, init_dataset):\n",
    "#         self._base_dataset = init_dataset\n",
    "        self._base_dataset = self.transform(init_dataset)\n",
    "    \n",
    "    def __len__(self):\n",
    "#         return len(self._base_dataset)\n",
    "        return self._base_dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return np.array(self._base_dataset[self._base_dataset.columns.drop('deal_probability')].iloc[idx].values, dtype=np.double), self._base_dataset['deal_probability'].iloc[idx]\n",
    "                \n",
    "    @staticmethod    \n",
    "    def transform(df):\n",
    "        if set(['image', 'image_top_1']).issubset(train_dataset.columns):\n",
    "            df.drop(['image', 'image_top_1'], axis=1, inplace=True)\n",
    "        for name in df.select_dtypes(include=['object', 'datetime64[ns]']).columns:\n",
    "            df[name] = df[name].astype('category')\n",
    "            cat_name = name + '_code'\n",
    "            df[cat_name] = df[name].cat.codes\n",
    "            df.drop([name], axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:25:46.327885Z",
     "start_time": "2022-02-09T07:25:29.362371Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"HW_data/train.csv\", parse_dates=[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:39:39.463262Z",
     "start_time": "2022-02-09T07:39:34.257789Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 15])\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(train_dataset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "for batch, label in train_loader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:47:43.484441Z",
     "start_time": "2022-02-09T07:47:43.467720Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.activation==\"relu\":\n",
    "            return F.relu(x)\n",
    "        if self.activation==\"sigmoid\":\n",
    "            return F.sigmoid(x)\n",
    "        raise RuntimeError\n",
    "        \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:47:44.820766Z",
     "start_time": "2022-02-09T07:47:44.810740Z"
    }
   },
   "outputs": [],
   "source": [
    "net = FeedForward(15, 10)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# use mean_squared_log_error from sklearn.metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Не разобрался почему не пошло обучение. Прошу подсказать.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T07:47:51.595931Z",
     "start_time": "2022-02-09T07:47:46.179763Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[5.5000e+03, 3.4000e+01, 1.0956e+06,  ..., 1.0537e+06, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 1.3327e+06,  ..., 1.0175e+06, 0.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [3.5000e+03, 3.3000e+01, 5.8670e+05,  ..., 8.7773e+05, 1.2000e+01,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [8.0000e+02, 3.0000e+01, 1.4976e+06,  ..., 1.1402e+05, 9.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.0000e+03, 2.9100e+02, 8.4320e+05,  ..., 1.1351e+06, 1.0000e+01,\n",
      "         1.0000e+00],\n",
      "        [3.8000e+03, 7.3000e+01, 7.2132e+05,  ..., 1.0761e+06, 2.0000e+00,\n",
      "         1.0000e+00]])\n",
      "labels: tensor([0.1387, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.5226, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7376,\n",
      "        0.0000, 0.8652, 0.0000, 0.0000, 0.1575, 0.0000, 0.0000, 0.0000, 0.2746,\n",
      "        0.0000, 0.0000, 0.5000, 0.0000, 0.0799, 0.0000, 0.1992, 0.0000, 0.0000,\n",
      "        0.0649, 0.2603, 0.0000, 0.3087, 0.0000, 0.0000, 0.0000, 0.0000, 0.3776,\n",
      "        0.0000, 0.0000, 0.1387, 0.0999, 0.0742, 0.0000, 0.0000, 0.1384, 0.0550,\n",
      "        0.7850, 0.0000, 0.0000, 0.7679, 0.1291, 0.0000, 0.0000, 0.2487, 0.0000,\n",
      "        0.0000, 0.0000, 0.2464, 0.0000, 0.8032, 0.8032, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0895, 0.0000, 0.0000, 0.0000, 0.8032, 0.6000, 0.8652,\n",
      "        0.2500, 0.0000, 0.0000, 0.8032, 0.0163, 0.1759, 0.0000, 0.0000, 0.0519,\n",
      "        0.0000, 0.2545, 0.0000, 0.8032, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0396, 0.0000, 0.0000, 0.0000, 0.7850, 0.7850, 0.0000, 0.0000,\n",
      "        0.7850, 0.0000, 0.2374, 0.0000, 0.0280, 0.6402, 0.0000, 0.1595, 0.0000,\n",
      "        0.3994, 0.2513, 0.0000, 0.0000, 0.8652, 0.0147, 0.0000, 0.4000, 0.0000,\n",
      "        0.1330, 0.0000], dtype=torch.float64)\n",
      "outpust: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10416/2879157203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'outpust: {outputs}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'labels: {labels.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_log_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;36m0.060\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \"\"\"\n\u001b[1;32m--> 515\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m     94\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = torch.Tensor(np.double(data[0])), data[1]\n",
    "        print(f'inputs: {inputs}')\n",
    "        print(f'labels: {labels}')\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        print(f'outpust: {outputs}')\n",
    "        loss = mean_squared_log_error(outputs, labels)\n",
    "        \n",
    "        print(f'labels: {labels.shape}')\n",
    "        print(f'outpust: {outputs}')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
