{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a24069a",
   "metadata": {},
   "source": [
    "# ДЗ к уроку 3\n",
    "Задача поиск похожих по эмбеддингам\n",
    "\n",
    "Скачиваем датасет (источник): положительные, отрицательные.\n",
    "\n",
    "или можно через ноутбук\n",
    "\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
    "\n",
    "что надо сделать\n",
    "1. объединить в одну выборку\n",
    "2. на основе word2vec/fasttext/glove/слоя Embedding реализовать метод поиска ближайших твитов\n",
    "(на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)\n",
    "3. Проверить насколько хорошо работают подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf32d8f",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112fa36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:20:33.062553Z",
     "start_time": "2022-05-04T17:20:28.238943Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import annoy\n",
    "import tqdm\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb8672",
   "metadata": {},
   "source": [
    "# Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd39c9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:50.036089Z",
     "start_time": "2022-05-04T17:32:49.295058Z"
    }
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = pd.concat([positive, negative])\n",
    "df = df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90c79b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f81e112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:51.793203Z",
     "start_time": "2022-05-04T17:32:51.782181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "104e0165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:52.231560Z",
     "start_time": "2022-05-04T17:32:52.214577Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(corpus):\n",
    "    \n",
    "    corpus = corpus.apply(str.lower)\n",
    "    \n",
    "    corpus = corpus.apply(lambda x: re.sub(r'@[\\w]*', '', x))\n",
    "#     Заменим пунктуацию на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "#     Заменим спец. символы на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^a-zA-Zа-яА-Я0-9ё]', ' ', x))\n",
    "#     Заменим числа на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^a-zA-Zа-яА-Яё]', ' ', x))\n",
    "#     Уберем слова менее 3 символов\n",
    "    corpus = corpus.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "#     Уберем стоп-слова\n",
    "    corpus = corpus.apply(lambda x: ' '.join([w for w in x.split() if not w in stop_words]))\n",
    "                          \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eca351a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:43:42.383281Z",
     "start_time": "2022-05-04T17:43:37.814390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         школота поверь самое общество профилирующий пр...\n",
       "1                          таки немного похож мальчик равно\n",
       "2                                        идиотка испугалась\n",
       "3         углу сидит погибает голода ещё порции взяли хо...\n",
       "4         значит страшилка блин посмотрев части создастс...\n",
       "                                ...                        \n",
       "226829               каждый хочет исправлять http qnoddqzuz\n",
       "226830                  скучаю вправляет мозги равно скучаю\n",
       "226831                                 школу говно это идти\n",
       "226832                                тауриэль грусти обнял\n",
       "226833    такси везет работу раздумываю приплатить втащи...\n",
       "Name: text, Length: 226834, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = preprocessing(df['text'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b26a8e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:43:42.399113Z",
     "start_time": "2022-05-04T17:43:42.385242Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    morpher = MorphAnalyzer()\n",
    "    \n",
    "    spls = \"\".join(i for i in line.strip()).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in stop_words and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4c6f3",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e039f33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:43:56.530582Z",
     "start_time": "2022-05-04T17:43:42.401085Z"
    }
   },
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=t, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95104a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:44:13.387978Z",
     "start_time": "2022-05-04T17:43:56.532533Z"
    }
   },
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=t, vector_size=300, min_count=1, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4731502b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T14:37:25.297171Z",
     "start_time": "2022-05-05T04:40:57.065974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddf043be7c64a9cbbfb80ff2add1279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "for line in tqdm.notebook.tqdm(t):\n",
    "    if len(line) > 0:\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split()\n",
    "    #     index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "\n",
    "        vector_w2v = np.zeros(300)\n",
    "        vector_ft = np.zeros(300)\n",
    "        for word in question:\n",
    "            if word in modelW2V.wv:\n",
    "                vector_w2v += modelW2V.wv[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f9cc1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:53:24.993343Z",
     "start_time": "2022-05-05T17:53:24.983343Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(question, index, model):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    return index.get_nns_by_vector(vector, 5 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5268179",
   "metadata": {},
   "source": [
    "# Результат\n",
    "\n",
    "Получим твиты ближайшие к запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a837a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:53:26.844260Z",
     "start_time": "2022-05-05T17:53:26.838264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запрос\n",
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68bc2f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:53:28.250783Z",
     "start_time": "2022-05-05T17:53:27.949635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717     @sbezrodnaya Светлана Борисовна,СПАСИБО за Нин...\n",
       "1295    P.S.   Послушать не дам. ЭТО даже я до конца д...\n",
       "1694    йоу скоро на танцули)\\nбудут говорить о Франци...\n",
       "1812    @GOTIMUS это верно, снова будем наблюдать как ...\n",
       "3113    Давайте руки как инопланетяне делать)\\nНастя,н...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[get_response(t[0], w2v_index, modelW2V), 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96d72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
