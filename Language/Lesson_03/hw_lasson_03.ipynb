{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a24069a",
   "metadata": {},
   "source": [
    "# ДЗ к уроку 3\n",
    "Задача поиск похожих по эмбеддингам\n",
    "\n",
    "Скачиваем датасет (источник): положительные, отрицательные.\n",
    "\n",
    "или можно через ноутбук\n",
    "\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
    "\n",
    "что надо сделать\n",
    "1. объединить в одну выборку\n",
    "2. на основе word2vec/fasttext/glove/слоя Embedding реализовать метод поиска ближайших твитов\n",
    "(на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)\n",
    "3. Проверить насколько хорошо работают подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf32d8f",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112fa36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:20:33.062553Z",
     "start_time": "2022-05-04T17:20:28.238943Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import annoy\n",
    "import tqdm\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb8672",
   "metadata": {},
   "source": [
    "# Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd39c9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:50.036089Z",
     "start_time": "2022-05-04T17:32:49.295058Z"
    }
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = pd.concat([positive, negative])\n",
    "df = df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90c79b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f81e112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:51.793203Z",
     "start_time": "2022-05-04T17:32:51.782181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "104e0165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:52.231560Z",
     "start_time": "2022-05-04T17:32:52.214577Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(corpus):\n",
    "    \n",
    "    corpus = corpus.apply(str.lower)\n",
    "    \n",
    "    corpus = corpus.apply(lambda x: re.sub(r'@[\\w]*', '', x))\n",
    "#     Заменим пунктуацию на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "#     Заменим спец. символы на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^a-zA-Zа-яА-Я0-9ё]', ' ', x))\n",
    "#     Заменим числа на пробелы\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^a-zA-Zа-яА-Яё]', ' ', x))\n",
    "#     Уберем слова менее 3 символов\n",
    "    corpus = corpus.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "#     Уберем стоп-слова\n",
    "    corpus = corpus.apply(lambda x: ' '.join([w for w in x.split() if not w in stop_words]))\n",
    "                          \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eca351a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:57.471097Z",
     "start_time": "2022-05-04T17:32:52.790466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      школота поверь самое общество профилирующий пр...\n",
       "1                       таки немного похож мальчик равно\n",
       "2                                     идиотка испугалась\n",
       "3      углу сидит погибает голода ещё порции взяли хо...\n",
       "4      значит страшилка блин посмотрев части создастс...\n",
       "                             ...                        \n",
       "995                        рискни рамку готовлю блинчики\n",
       "996          спасибо считаю найти свое место очень важно\n",
       "997    уаааа около прошел паренек чисто женской поход...\n",
       "998           монгол коментийн vзэж жаахан хэрэгт дурлая\n",
       "999              анютка любит поезда осторожнее ирисками\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = preprocessing(df['text'])[:1000]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b26a8e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:32:57.487104Z",
     "start_time": "2022-05-04T17:32:57.473097Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    morpher = MorphAnalyzer()\n",
    "    \n",
    "    spls = \"\".join(i for i in line.strip()).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in stop_words and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4c6f3",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e039f33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:33:00.828178Z",
     "start_time": "2022-05-04T17:33:00.702132Z"
    }
   },
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=t, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95104a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:33:04.127374Z",
     "start_time": "2022-05-04T17:33:01.669748Z"
    }
   },
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=t, vector_size=300, min_count=1, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4731502b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:35:45.993461Z",
     "start_time": "2022-05-04T17:33:05.313258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20816\\3581189489.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm.tqdm_notebook(t):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948923709cb742278f7ea8aff05aad7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "for line in tqdm.tqdm_notebook(t):\n",
    "    try:\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split()\n",
    "    #     index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "\n",
    "        vector_w2v = np.zeros(300)\n",
    "        vector_ft = np.zeros(300)\n",
    "        for word in question:\n",
    "            if word in modelW2V.wv:\n",
    "                vector_w2v += modelW2V.wv[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if counter > 100000:\n",
    "            break\n",
    "    except:\n",
    "        print(f'Error! Count: {counter} line: \"{line}\"')\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f9cc1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:35:46.008430Z",
     "start_time": "2022-05-04T17:35:45.996442Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(question, index, model):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    return index.get_nns_by_vector(vector, 5 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd2f91",
   "metadata": {},
   "source": [
    "# Результат\n",
    "\n",
    "Получим твиты ближайшие к запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "507502bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:40:44.675736Z",
     "start_time": "2022-05-04T17:40:44.660743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запрос\n",
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68bc2f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T17:40:47.227190Z",
     "start_time": "2022-05-04T17:40:46.947167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Да, все-таки он немного похож на него. Но мой ...\n",
       "5     ну любишь или нет? — Я не знаю кто ты бля:D ht...\n",
       "9     Теперь у меня есть частичка Сиднея :) #Sydney ...\n",
       "11    RT @dicyziqecida: Как-то я забыла, что вчера п...\n",
       "18    @xLesherx @4EU3 зря вы с этой хуйней шутите)) ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[get_response(t[0], w2v_index, modelW2V), 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2a854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
