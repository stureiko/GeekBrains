{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ace2d2",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb748c",
   "metadata": {},
   "source": [
    "___Не успел закончить (был в коммандировке неделю), оставляю зашлушку за выходные до 25.04 закончу.___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b969bb7",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d44488",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3030ed6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:01:46.855121Z",
     "start_time": "2022-04-22T03:01:46.848245Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77d430d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:09.313858Z",
     "start_time": "2022-04-21T10:30:08.189443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when father is dysfunctional and is so se...</td>\n",
       "      <td>[user, when, father, is, dysfunctional, and, i...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drags, ...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks for lyft credit can use cause...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, can, u...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, cause,...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love take with all the time in ur</td>\n",
       "      <td>[model, love, take, with, all, the, time, in, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clear_tweet  \\\n",
       "0  user when father is dysfunctional and is so se...   \n",
       "1  user user thanks for lyft credit can use cause...   \n",
       "2                                bihday your majesty   \n",
       "3            model love take with all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [user, when, father, is, dysfunctional, and, i...   \n",
       "1  [user, user, thanks, for, lyft, credit, can, u...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, take, with, all, the, time, in, ur]   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [user, father, dysfunctional, selfish, drags, ...   \n",
       "1  [user, user, thanks, lyft, credit, use, cause,...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...   \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...  \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...  \n",
       "2                                  [bihday, majesti]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                        [factsguid, societi, motiv]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../Lesson_01/lesson_01_preprocessing.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077d2ff",
   "metadata": {},
   "source": [
    "Проверим на пропуски столбец ``'label'`` и отсутствующие заполним ``0`` (на этой итерации)\n",
    "\n",
    "\n",
    "Затем построим классификатор и на его основании предскажем метки твитов с пропущенными метками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc836814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:12.088620Z",
     "start_time": "2022-04-21T10:30:12.076731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628748cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:14.788988Z",
     "start_time": "2022-04-21T10:30:14.778061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    29720\n",
       "1.0     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d3fb38b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:15.814313Z",
     "start_time": "2022-04-21T10:30:15.804882Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e848683b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:17.208888Z",
     "start_time": "2022-04-21T10:30:17.191550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46917\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f574faf",
   "metadata": {},
   "source": [
    "### Выделим метки и разделим на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed836d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ca92b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T02:27:03.829952Z",
     "start_time": "2022-04-22T02:27:03.739086Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = df['tweet_stemmed'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = [\" \".join(x) for x in X_train]\n",
    "X_test = [\" \".join(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4355c",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42e81aa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T02:24:02.784015Z",
     "start_time": "2022-04-22T02:24:02.727622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user', 'father']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [x for l in df['tweet_stemmed'] for x in l]\n",
    "print(len(corpus))\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d4c7810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T02:24:12.171355Z",
     "start_time": "2022-04-22T02:24:12.026234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 27137),\n",
       " ('love', 5016),\n",
       " ('day', 4423),\n",
       " ('happi', 3285),\n",
       " ('amp', 2710),\n",
       " ('thank', 2407),\n",
       " ('time', 1957),\n",
       " ('get', 1943),\n",
       " ('like', 1828),\n",
       " ('life', 1797)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fec94cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:02:03.276256Z",
     "start_time": "2022-04-22T03:01:59.983617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98     15793\n",
      "         1.0       0.33      0.58      0.42       430\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.66      0.77      0.70     16223\n",
      "weighted avg       0.97      0.96      0.96     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46c2a129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:02:48.756007Z",
     "start_time": "2022-04-22T03:02:42.976301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98     15805\n",
      "         1.0       0.34      0.61      0.43       418\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.66      0.79      0.71     16223\n",
      "weighted avg       0.97      0.96      0.96     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 2), binary=False)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc3f9c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:06:24.256898Z",
     "start_time": "2022-04-22T03:06:18.702202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98     16052\n",
      "         1.0       0.13      0.60      0.22       171\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.56      0.78      0.60     16223\n",
      "weighted avg       0.99      0.96      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2))\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60f24323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:08:15.072085Z",
     "start_time": "2022-04-22T03:08:15.057547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.30373964, 10.70920474, 10.70920474, ..., 10.70920474,\n",
       "       10.70920474, 10.70920474])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7076bfc",
   "metadata": {},
   "source": [
    "## Получить наиболее значимые фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe57eb9",
   "metadata": {},
   "source": [
    "Не помоню - посмотри в инете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8db25",
   "metadata": {},
   "source": [
    "## Попробуем сетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75579085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:52:24.794505Z",
     "start_time": "2022-04-22T03:52:24.786106Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60781d76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:54:59.416126Z",
     "start_time": "2022-04-22T03:54:59.210795Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1202d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:55:40.023077Z",
     "start_time": "2022-04-22T03:55:40.014282Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.batch(10)\n",
    "test_data = test_data.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "86d73f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:58:25.800171Z",
     "start_time": "2022-04-22T03:58:25.796398Z"
    }
   },
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64b0b7d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:59:25.028688Z",
     "start_time": "2022-04-22T03:59:25.022758Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_standartization(input_data):\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e98d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "seq_len = 100\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
