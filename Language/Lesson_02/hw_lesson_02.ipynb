{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e973e2",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051b3c8",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24370c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T09:09:17.466884Z",
     "start_time": "2022-04-21T09:09:17.460516Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7abdcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T09:08:46.328477Z",
     "start_time": "2022-04-21T09:08:45.461882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when father is dysfunctional and is so se...</td>\n",
       "      <td>[user, when, father, is, dysfunctional, and, i...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drags, ...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks for lyft credit can use cause...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, can, u...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, cause,...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love take with all the time in ur</td>\n",
       "      <td>[model, love, take, with, all, the, time, in, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clear_tweet  \\\n",
       "0  user when father is dysfunctional and is so se...   \n",
       "1  user user thanks for lyft credit can use cause...   \n",
       "2                                bihday your majesty   \n",
       "3            model love take with all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [user, when, father, is, dysfunctional, and, i...   \n",
       "1  [user, user, thanks, for, lyft, credit, can, u...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, take, with, all, the, time, in, ur]   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [user, father, dysfunctional, selfish, drags, ...   \n",
       "1  [user, user, thanks, lyft, credit, use, cause,...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...   \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...  \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...  \n",
       "2                                  [bihday, majesti]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                        [factsguid, societi, motiv]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../Lesson_01/lesson_01_preprocessing.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f14fc",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739150f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T09:18:43.725335Z",
     "start_time": "2022-04-21T09:18:43.687275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user', 'father']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [x for l in df['tweet_stemmed'] for x in l]\n",
    "print(len(corpus))\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52c6456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T09:18:51.322618Z",
     "start_time": "2022-04-21T09:18:51.166114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 27137),\n",
       " ('love', 5016),\n",
       " ('day', 4423),\n",
       " ('happi', 3285),\n",
       " ('amp', 2710),\n",
       " ('thank', 2407),\n",
       " ('time', 1957),\n",
       " ('get', 1943),\n",
       " ('like', 1828),\n",
       " ('life', 1797)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cb40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
