{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1c67f4",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cc440",
   "metadata": {},
   "source": [
    "___Не успел закончить (был в коммандировке неделю), оставляю зашлушку за выходные до 25.04 закончу.___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559eb1b",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da78928",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3ba8af37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:56:44.349653Z",
     "start_time": "2022-04-23T06:56:44.338968Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd2b5311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:09.313858Z",
     "start_time": "2022-04-21T10:30:08.189443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clear_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when father is dysfunctional and is so se...</td>\n",
       "      <td>[user, when, father, is, dysfunctional, and, i...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drags, ...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "      <td>[user, father, dysfunct, selfish, drag, kid, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks for lyft credit can use cause...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, can, u...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, cause,...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "      <td>[user, user, thank, lyft, credit, use, caus, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love take with all the time in ur</td>\n",
       "      <td>[model, love, take, with, all, the, time, in, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clear_tweet  \\\n",
       "0  user when father is dysfunctional and is so se...   \n",
       "1  user user thanks for lyft credit can use cause...   \n",
       "2                                bihday your majesty   \n",
       "3            model love take with all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [user, when, father, is, dysfunctional, and, i...   \n",
       "1  [user, user, thanks, for, lyft, credit, can, u...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, take, with, all, the, time, in, ur]   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [user, father, dysfunctional, selfish, drags, ...   \n",
       "1  [user, user, thanks, lyft, credit, use, cause,...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...   \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [user, father, dysfunct, selfish, drag, kid, d...  \n",
       "1  [user, user, thank, lyft, credit, use, caus, o...  \n",
       "2                                  [bihday, majesti]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                        [factsguid, societi, motiv]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../Lesson_01/lesson_01_preprocessing.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a412ab0",
   "metadata": {},
   "source": [
    "Проверим на пропуски столбец ``'label'`` и отсутствующие заполним ``0`` (на этой итерации)\n",
    "\n",
    "\n",
    "Затем построим классификатор и на его основании предскажем метки твитов с пропущенными метками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bbc49d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:12.088620Z",
     "start_time": "2022-04-21T10:30:12.076731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0e73c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:14.788988Z",
     "start_time": "2022-04-21T10:30:14.778061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    29720\n",
       "1.0     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9a84028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:15.814313Z",
     "start_time": "2022-04-21T10:30:15.804882Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "170b0ad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T10:30:17.208888Z",
     "start_time": "2022-04-21T10:30:17.191550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46917\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c814dd",
   "metadata": {},
   "source": [
    "### Выделим метки и разделим на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6c1b314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T02:27:03.829952Z",
     "start_time": "2022-04-22T02:27:03.739086Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = df['tweet_stemmed'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = [\" \".join(x) for x in X_train]\n",
    "X_test = [\" \".join(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddfa20",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1877daf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:04.367817Z",
     "start_time": "2022-04-23T06:30:04.359117Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_freq = pd.DataFrame(columns=['Token_frequency', 'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fa545160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:09.018698Z",
     "start_time": "2022-04-23T06:30:06.868903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98     15793\n",
      "         1.0       0.33      0.58      0.42       430\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.66      0.77      0.70     16223\n",
      "weighted avg       0.97      0.96      0.96     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на всех токенах\n",
    "vec = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=1,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "\n",
    "compare_freq.loc[compare_freq.shape[0]] = ['All tokens', f1_score(y_true=y_test, y_pred=pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a5b17d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:11.115461Z",
     "start_time": "2022-04-23T06:30:09.028087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98     15783\n",
      "         1.0       0.34      0.59      0.43       440\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.66      0.78      0.70     16223\n",
      "weighted avg       0.97      0.96      0.96     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах с низкой частотой (максимум в 30% документов)\n",
    "vec = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.3, \n",
    "                      min_df=1,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[compare_freq.shape[0]] = ['Low frequency tokens', f1_score(y_true=y_test, y_pred=pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a5c68d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:12.276597Z",
     "start_time": "2022-04-23T06:30:11.119297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16043\n",
      "         1.0       0.12      0.52      0.20       180\n",
      "\n",
      "    accuracy                           0.95     16223\n",
      "   macro avg       0.56      0.74      0.59     16223\n",
      "weighted avg       0.98      0.95      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах с высокой частотой (минимум в 100 документах)\n",
    "vec = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=100,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[compare_freq.shape[0]] = ['High frequency tokens', f1_score(y_true=y_test, y_pred=pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cfaf4170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:13.734104Z",
     "start_time": "2022-04-23T06:30:12.281737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16043\n",
      "         1.0       0.12      0.52      0.20       180\n",
      "\n",
      "    accuracy                           0.95     16223\n",
      "   macro avg       0.56      0.74      0.59     16223\n",
      "weighted avg       0.98      0.95      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах средней частоты\n",
    "vec = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.7, \n",
    "                      min_df=100,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[compare_freq.shape[0]] = ['Middle frequency tokens', f1_score(y_true=y_test, y_pred=pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "efbd4a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:13.773716Z",
     "start_time": "2022-04-23T06:30:13.740483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_frequency</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All tokens</td>\n",
       "      <td>0.420521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low frequency tokens</td>\n",
       "      <td>0.430359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middle frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token_frequency  f1_score\n",
       "0               All tokens  0.420521\n",
       "1     Low frequency tokens  0.430359\n",
       "2    High frequency tokens  0.198083\n",
       "3  Middle frequency tokens  0.198083"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "76549575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:30:24.905965Z",
     "start_time": "2022-04-23T06:30:24.884405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_frequency</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>TFIDF_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All tokens</td>\n",
       "      <td>0.420521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low frequency tokens</td>\n",
       "      <td>0.430359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middle frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token_frequency  f1_score  TFIDF_f1_score\n",
       "0               All tokens  0.420521               0\n",
       "1     Low frequency tokens  0.430359               0\n",
       "2    High frequency tokens  0.198083               0\n",
       "3  Middle frequency tokens  0.198083               0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_freq['TFIDF_f1_score'] = 0\n",
    "compare_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "11f4e532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:31:54.254610Z",
     "start_time": "2022-04-23T06:31:53.182798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16048\n",
      "         1.0       0.12      0.54      0.20       175\n",
      "\n",
      "    accuracy                           0.95     16223\n",
      "   macro avg       0.56      0.75      0.59     16223\n",
      "weighted avg       0.99      0.95      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах средней частоты\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.7, \n",
    "                      min_df=100,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[3, 'TFIDF_f1_score'] = f1_score(y_true=y_test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cbafc71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:36:34.526004Z",
     "start_time": "2022-04-23T06:36:32.816204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16027\n",
      "         1.0       0.16      0.60      0.25       196\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.58      0.78      0.61     16223\n",
      "weighted avg       0.98      0.96      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на всех токенах\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=1)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[0, 'TFIDF_f1_score'] = f1_score(y_true=y_test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0291b39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:34:10.629867Z",
     "start_time": "2022-04-23T06:34:08.411723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16027\n",
      "         1.0       0.15      0.60      0.25       196\n",
      "\n",
      "    accuracy                           0.96     16223\n",
      "   macro avg       0.57      0.78      0.61     16223\n",
      "weighted avg       0.98      0.96      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах низкой частоты\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.3, \n",
    "                      min_df=1,)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[1, 'TFIDF_f1_score'] = f1_score(y_true=y_test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2f65e822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:37:30.256602Z",
     "start_time": "2022-04-23T06:37:29.029016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     16048\n",
      "         1.0       0.12      0.54      0.20       175\n",
      "\n",
      "    accuracy                           0.95     16223\n",
      "   macro avg       0.56      0.75      0.59     16223\n",
      "weighted avg       0.99      0.95      0.97     16223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучим на токенах высокой частоты\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=100)\n",
    "bow = vec.fit_transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "print(classification_report(pred, y_test))\n",
    "compare_freq.loc[2, 'TFIDF_f1_score'] = f1_score(y_true=y_test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2eeab43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T06:37:32.870672Z",
     "start_time": "2022-04-23T06:37:32.854553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_frequency</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>TFIDF_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All tokens</td>\n",
       "      <td>0.420521</td>\n",
       "      <td>0.247120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low frequency tokens</td>\n",
       "      <td>0.430359</td>\n",
       "      <td>0.201285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0.201285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middle frequency tokens</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0.201285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token_frequency  f1_score  TFIDF_f1_score\n",
       "0               All tokens  0.420521        0.247120\n",
       "1     Low frequency tokens  0.430359        0.201285\n",
       "2    High frequency tokens  0.198083        0.201285\n",
       "3  Middle frequency tokens  0.198083        0.201285"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433828b",
   "metadata": {},
   "source": [
    "__Задание 1 - наиболее выжными оказались токены встречающиеся редко - для них наибольшее значение f1 score по классу 1, и примерно постоянное значение по классу 0.__\n",
    "\n",
    "TFIDF учитывает частоту вхождения поэтому здесь лучше для всех токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499bd7e",
   "metadata": {},
   "source": [
    "## Задание 2. \n",
    "Получить наиболее значимые фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f6131",
   "metadata": {},
   "source": [
    "Не помоню - посмотри в инете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3c330",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "249cecc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T07:07:18.589995Z",
     "start_time": "2022-04-23T07:07:02.138377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:16<00:00,  1.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>0.247120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(min_df=100)</td>\n",
       "      <td>0.201285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer(max_df=0.7, min_df=100)</td>\n",
       "      <td>0.201285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer(max_df=0.3)</td>\n",
       "      <td>0.245026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>0.420521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CountVectorizer(min_df=100)</td>\n",
       "      <td>0.198083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CountVectorizer(max_df=0.7, min_df=100)</td>\n",
       "      <td>0.198083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CountVectorizer(max_df=0.3)</td>\n",
       "      <td>0.430359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(n_features=9900)</td>\n",
       "      <td>0.234542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Vectorizer  f1_score\n",
       "0                        TfidfVectorizer()  0.247120\n",
       "1              TfidfVectorizer(min_df=100)  0.201285\n",
       "2  TfidfVectorizer(max_df=0.7, min_df=100)  0.201285\n",
       "3              TfidfVectorizer(max_df=0.3)  0.245026\n",
       "4                        CountVectorizer()  0.420521\n",
       "5              CountVectorizer(min_df=100)  0.198083\n",
       "6  CountVectorizer(max_df=0.7, min_df=100)  0.198083\n",
       "7              CountVectorizer(max_df=0.3)  0.430359\n",
       "8       HashingVectorizer(n_features=9900)  0.234542"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizers = []\n",
    "\n",
    "vec_TFIDF_all = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=1)\n",
    "vectorizers.append(vec_TFIDF_all)\n",
    "\n",
    "vec_TFIDF_high = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=100)\n",
    "vectorizers.append(vec_TFIDF_high)\n",
    "\n",
    "vec_TFIDF_middle = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.7, \n",
    "                      min_df=100)\n",
    "vectorizers.append(vec_TFIDF_middle)\n",
    "\n",
    "vec_TFIDF_low = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.3, \n",
    "                      min_df=1)\n",
    "vectorizers.append(vec_TFIDF_low)\n",
    "\n",
    "vec_count_all = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=1)\n",
    "vectorizers.append(vec_count_all)\n",
    "\n",
    "vec_count_high = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=1.0, \n",
    "                      min_df=100)\n",
    "vectorizers.append(vec_count_high)\n",
    "\n",
    "vec_count_middle = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.7, \n",
    "                      min_df=100)\n",
    "vectorizers.append(vec_count_middle)\n",
    "\n",
    "vec_count_low = CountVectorizer(ngram_range=(1, 1), \n",
    "                      binary=False, \n",
    "                      max_df=0.3, \n",
    "                      min_df=1)\n",
    "vectorizers.append(vec_count_low)\n",
    "\n",
    "vec_hash = HashingVectorizer(n_features=9900)\n",
    "vectorizers.append(vec_hash)\n",
    "\n",
    "compare = pd.DataFrame(columns=['Vectorizer', 'f1_score'])\n",
    "\n",
    "for vec in tqdm(vectorizers):\n",
    "    bow = vec.fit_transform(X_train)\n",
    "\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    clf.fit(bow, y_train)\n",
    "\n",
    "    pred = clf.predict(vec.transform(X_test))\n",
    "#     print(classification_report(pred, y_test))\n",
    "    compare.loc[compare.shape[0]] = [str(vec), f1_score(y_true=y_test, y_pred=pred)]\n",
    "\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "740f7560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T07:07:34.374495Z",
     "start_time": "2022-04-23T07:07:34.362805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vectorizer    TfidfVectorizer(min_df=100)\n",
       "f1_score                         0.430359\n",
       "dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7987a0dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T07:06:15.747452Z",
     "start_time": "2022-04-23T07:02:29.794593Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 199/199 [03:45<00:00,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vectorizer    HashingVectorizer(n_features=9900)\n",
       "f1_score                                0.251055\n",
       "dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подбор для HashingVectorizer\n",
    "vectorizers = []\n",
    "compare = pd.DataFrame(columns=['Vectorizer', 'f1_score'])\n",
    "\n",
    "for n in np.arange(100, 20000, 100):\n",
    "    vec_hash = HashingVectorizer(n_features=n)\n",
    "    vectorizers.append(vec_hash)\n",
    "\n",
    "for vec in tqdm(vectorizers):\n",
    "    bow = vec.fit_transform(X_train)\n",
    "\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    clf.fit(bow, y_train)\n",
    "\n",
    "    pred = clf.predict(vec.transform(X_test))\n",
    "#     print(classification_report(pred, y_test))\n",
    "    compare.loc[compare.shape[0]] = [str(vec), f1_score(y_true=y_test, y_pred=pred)]\n",
    "\n",
    "compare.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd90cf",
   "metadata": {},
   "source": [
    "## Попробуем сетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f380228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:52:24.794505Z",
     "start_time": "2022-04-22T03:52:24.786106Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a801f657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:54:59.416126Z",
     "start_time": "2022-04-22T03:54:59.210795Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "96b26869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:55:40.023077Z",
     "start_time": "2022-04-22T03:55:40.014282Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.batch(10)\n",
    "test_data = test_data.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc799d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:58:25.800171Z",
     "start_time": "2022-04-22T03:58:25.796398Z"
    }
   },
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "579b5849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T03:59:25.028688Z",
     "start_time": "2022-04-22T03:59:25.022758Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_standartization(input_data):\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f52717",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "seq_len = 100\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
