{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0d99cf",
   "metadata": {},
   "source": [
    "# Задание 1. Написать теггер на данных с русским языком\n",
    "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n",
    "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "3. сравнить все реализованные методы сделать выводы\n",
    "\n",
    "# Задание 2. Проверить насколько хорошо работает NER\n",
    "данные брать из http://www.labinform.ru/pub/named_entities/\n",
    "1. проверить NER из nltk/spacy/deeppavlov\n",
    "2. написать свой нер попробовать разные подходы\n",
    "   1. передаём в сетку токен и его соседей\n",
    "   2. передаём в сетку только токен\n",
    "3. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b001a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from corus import load_ne5\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b164db",
   "metadata": {},
   "source": [
    "## Написать теггер на данных с русским языком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f1cf4",
   "metadata": {},
   "source": [
    "Работать с русским языком будем на скачанных данных из Роспотребнадзора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d7a407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Lesson_04/question.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9ac521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Получила не качественную услугу в «Центр косме...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ведётся продажа контрафакта г.к Анапа ул Астра...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question\n",
       "0           0  Получила не качественную услугу в «Центр косме...\n",
       "1           1  Ведётся продажа контрафакта г.к Анапа ул Астра..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f725404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stureiko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     /Users/stureiko/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "words_regex = re.compile('\\w+')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_ru')\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def find_words(text, regex = words_regex):\n",
    "    tokens =  regex.findall(text.lower())\n",
    "    return [w for w in tokens if w.isalpha() and len(w) >= 3]\n",
    "\n",
    "\n",
    "stopwords_list = stopwords.words('russian')\n",
    "\n",
    "\n",
    "def lemmatize(words, lemmer = morph, stopwords = stopwords_list):\n",
    "    lemmas = [lemmer.parse(w)[0].normal_form for w in words]\n",
    "    return [w for w in lemmas if not w in stopwords \n",
    "            and w.isalpha()]\n",
    "\n",
    "def preprocess(text):\n",
    "    return (lemmatize(find_words(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b44b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3822bc6e2f4a7ab0b7fddbed78278b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_text = list(tqdm(map(preprocess, df['question']), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3edaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bfca34a72847039985f82711b68ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = list(tqdm(map(find_words, df['question']), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9ecacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = words[1:int(len(words) * 0.9)]\n",
    "test_data = words[int(len(words) * 0.9):]\n",
    "test_sent = words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68d3e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [nltk.pos_tag(i, lang = 'rus') for i in train_data]\n",
    "test_data = [nltk.pos_tag(i, lang = 'rus') for i in test_data]\n",
    "# test_sent = nltk.pos_tag(test_sent, lang = 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "763cb69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/6f78t4jn60s5_ntqqc2dj0980000gn/T/ipykernel_27030/1149866346.py:2: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  display(unigram_tagger.tag(test_sent), unigram_tagger.evaluate(test_data))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('получила', 'V'),\n",
       " ('качественную', None),\n",
       " ('услугу', 'S'),\n",
       " ('центр', 'S'),\n",
       " ('косметологии', None),\n",
       " ('лица', 'S'),\n",
       " ('или', 'CONJ'),\n",
       " ('ооо', 'S'),\n",
       " ('тиэльбьюти', None),\n",
       " ('киров', 'S'),\n",
       " ('красноармейская', None),\n",
       " ('процедура', 'S'),\n",
       " ('увеличение', None),\n",
       " ('губ', None),\n",
       " ('филлером', None),\n",
       " ('выполнял', None),\n",
       " ('услугу', 'S'),\n",
       " ('директор', 'S'),\n",
       " ('салона', None),\n",
       " ('лысова', None),\n",
       " ('татьяна', 'S'),\n",
       " ('евгеньевна', None),\n",
       " ('путем', 'S'),\n",
       " ('долгих', None),\n",
       " ('переговоров', None),\n",
       " ('через', 'PR'),\n",
       " ('письменную', None),\n",
       " ('претензию', 'S'),\n",
       " ('денежные', 'A=pl'),\n",
       " ('средства', 'S'),\n",
       " ('вернули', 'V'),\n",
       " ('очень', 'ADV'),\n",
       " ('хотели', None),\n",
       " ('возвращать', 'V'),\n",
       " ('утверждая', None),\n",
       " ('что', 'CONJ'),\n",
       " ('это', 'S-PRO'),\n",
       " ('моя', 'A-PRO=f'),\n",
       " ('вина', None),\n",
       " ('хотя', 'CONJ'),\n",
       " ('этого', 'S-PRO'),\n",
       " ('делала', None),\n",
       " ('данную', 'A-PRO=f'),\n",
       " ('процедуру', None),\n",
       " ('других', 'A-PRO=pl'),\n",
       " ('косметологов', None),\n",
       " ('всё', 'S-PRO'),\n",
       " ('было', 'V'),\n",
       " ('хорошо', 'ADV'),\n",
       " ('доставили', 'V'),\n",
       " ('много', 'NUM=nom'),\n",
       " ('дискомфорта', None),\n",
       " ('как', 'CONJ'),\n",
       " ('морального', 'A=m'),\n",
       " ('так', 'ADV-PRO'),\n",
       " ('материального', None),\n",
       " ('изучила', 'V'),\n",
       " ('всю', 'A-PRO=f'),\n",
       " ('информацию', 'S'),\n",
       " ('данном', 'A-PRO=m'),\n",
       " ('так', 'ADV-PRO'),\n",
       " ('называемом', None),\n",
       " ('косметологе', None),\n",
       " ('выяснилось', 'V'),\n",
       " ('что', 'CONJ'),\n",
       " ('салона', None),\n",
       " ('есть', 'V'),\n",
       " ('медицинская', None),\n",
       " ('лицензия', 'S'),\n",
       " ('самого', 'A-PRO=m'),\n",
       " ('косметолога', None),\n",
       " ('нет', 'PRAEDIC'),\n",
       " ('образования', 'S'),\n",
       " ('врача', 'S'),\n",
       " ('высшее', None),\n",
       " ('что', 'CONJ'),\n",
       " ('дает', 'V'),\n",
       " ('право', 'S'),\n",
       " ('выполнение', None),\n",
       " ('инъекций', None),\n",
       " ('прочих', None),\n",
       " ('вмешательств', None),\n",
       " ('данный', 'A-PRO=m'),\n",
       " ('человек', 'S'),\n",
       " ('имеется', 'V'),\n",
       " ('право', 'S'),\n",
       " ('выполнять', 'V'),\n",
       " ('такие', 'A-PRO=pl'),\n",
       " ('услуги', 'S'),\n",
       " ('образованне', None),\n",
       " ('среднее', None),\n",
       " ('специальное', None),\n",
       " ('мед', 'A=pl'),\n",
       " ('колледж', None),\n",
       " ('высшее', None),\n",
       " ('экономическое', 'A=n'),\n",
       " ('врача', 'S'),\n",
       " ('данного', 'A-PRO=m'),\n",
       " ('мастера', 'S'),\n",
       " ('имеется', 'V'),\n",
       " ('только', 'PART'),\n",
       " ('сертификат', 'S'),\n",
       " ('что', 'CONJ'),\n",
       " ('проходила', None),\n",
       " ('курсы', None),\n",
       " ('увеличения', None),\n",
       " ('губ', None),\n",
       " ('без', 'PR'),\n",
       " ('диплома', None),\n",
       " ('врача', 'S'),\n",
       " ('нельзя', 'PRAEDIC'),\n",
       " ('данный', 'A-PRO=m'),\n",
       " ('мастер', 'S'),\n",
       " ('имеет', 'V'),\n",
       " ('права', 'S'),\n",
       " ('работать', None),\n",
       " ('косметологом', None),\n",
       " ('без', 'PR'),\n",
       " ('должного', None),\n",
       " ('образования', 'S'),\n",
       " ('оказывать', None),\n",
       " ('такого', 'A-PRO=m'),\n",
       " ('рода', None),\n",
       " ('услуги', 'S'),\n",
       " ('есть', 'V'),\n",
       " ('аудио', 'S'),\n",
       " ('запись', 'S'),\n",
       " ('разговора', None),\n",
       " ('последнем', None),\n",
       " ('визите', 'S')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6776171703898379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(train_data)\n",
    "# display(unigram_tagger.tag(test_sent))\n",
    "unigram_tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b77f8c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/6f78t4jn60s5_ntqqc2dj0980000gn/T/ipykernel_27030/523054775.py:3: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  bigram_tagger.evaluate(test_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6811213315812528"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
    "# display(bigram_tagger.tag(test_sent))\n",
    "bigram_tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6831932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/6f78t4jn60s5_ntqqc2dj0980000gn/T/ipykernel_27030/3676292912.py:3: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  trigram_tagger.evaluate(test_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6811213315812528"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n",
    "# display(trigram_tagger.tag(test_sent))\n",
    "trigram_tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44d61445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/6f78t4jn60s5_ntqqc2dj0980000gn/T/ipykernel_27030/2738799135.py:12: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  tag.evaluate(test_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6811213315812528"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "\n",
    "backoff = DefaultTagger('NN') \n",
    "tag = backoff_tagger(train_data,  \n",
    "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "tag.evaluate(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83689190",
   "metadata": {},
   "source": [
    "___В отличии от английского языка   для русского nltk работает хуже и на триграме и комбинации тегеров не дает прироста качества___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d020c",
   "metadata": {},
   "source": [
    "## Написать свой теггер как на занятии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b87f6",
   "metadata": {},
   "source": [
    "Сделаем словарик русских имен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3b68586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "\n",
    "\n",
    "t_df = pd.DataFrame(columns = ['index', 'type', 'text'])\n",
    "for item in records:\n",
    "    for i in item.spans:\n",
    "        if i.type == 'PER':\n",
    "            t_df.loc[len(t_df)] = [i.index, i.type, i.text] \n",
    "\n",
    "names = list(set(t_df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79984d",
   "metadata": {},
   "source": [
    "Помимо полных имен (ФИО) выделим только имена и добавим их в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3c41413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f2e72da5b4484084e5d3d0233788c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1423334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_n = []\n",
    "for s in tqdm(names):\n",
    "    full_n.append(s)\n",
    "    full_n.append(nltk.word_tokenize(s)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aedefbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import SequentialBackoffTagger\n",
    "\n",
    "class NamesTagger(SequentialBackoffTagger):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        SequentialBackoffTagger.__init__(self, *args, **kwargs)\n",
    "        self.name_set = set([n.lower() for n in full_n])\n",
    "            \n",
    "    def choose_tag(self, tokens, index, history):\n",
    "        word = tokens[index]\n",
    "        if word.lower() in self.name_set:\n",
    "             return 'NNP'\n",
    "        else:\n",
    "             return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dabf9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Екатерина', 'NNP')]\n",
      "[('Александр Рогачев', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "nt = NamesTagger()\n",
    "print(nt.tag(['Екатерина'])) \n",
    "print(nt.tag(['Александр Рогачев'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4040d",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fba95",
   "metadata": {},
   "source": [
    "## Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b16b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c664b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "\n",
    "text = df['question'][0]\n",
    "doc = Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85f42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Получила VERB|Aspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "                  не PART|Polarity=Neg\n",
      "        качественную ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "              услугу NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      "                   в ADP\n",
      "                   « PUNCT\n",
      "               Центр NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
      "        косметологии NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "                лица NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "                   » PUNCT\n",
      "                 или CCONJ\n",
      "                 ООО PROPN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "                   « PUNCT\n",
      "          ТИЭЛЬБЬЮТИ NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "                   » PUNCT\n",
      "                   г NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   . PUNCT\n",
      "               Киров PROPN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "     Красноармейская ADJ|Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\n",
      "                  41 NUM\n",
      "                   . PUNCT\n",
      "           Процедура NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "                   » PUNCT\n",
      "          Увеличение NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
      "                 губ NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
      "            филлером NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   » PUNCT\n",
      "                   . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.parse_syntax(syntax_parser)\n",
    "sent = doc.sents[0]\n",
    "sent.morph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cac209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Получила        \n",
      "          ┌► не              advmod\n",
      "        ┌►└─ качественную    amod\n",
      "      ┌─└─── услугу          \n",
      "      │ ┌──► в               case\n",
      "      │ │ ┌► «               punct\n",
      "  ┌─┌─└►└─└─ Центр           nmod\n",
      "  │ │ │ └──► косметологии    nmod\n",
      "  │ │ └────► лица            nmod\n",
      "  │ └──────► »               punct\n",
      "  │       ┌► или             cc\n",
      "┌─└──►┌─┌─└─ ООО             conj\n",
      "│     │ │ ┌► «               punct\n",
      "│     │ └►└─ ТИЭЛЬБЬЮТИ      appos\n",
      "│     │ └──► »               punct\n",
      "│     └──►┌─ г               appos\n",
      "│     ┌──►│  .               punct\n",
      "│     │ ┌─└► Киров           amod\n",
      "└────►│ │    Красноармейская appos\n",
      "      │ └──► 41              appos\n",
      "      │      .               \n",
      "      └─┌─── Процедура       \n",
      "        │ ┌► »               punct\n",
      "      ┌─└►└─ Увеличение      appos\n",
      "      │ └►┌─ губ             nmod\n",
      "      │   └► филлером        nmod\n",
      "      └────► »               punct\n",
      "             .               \n"
     ]
    }
   ],
   "source": [
    "sent.syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c4622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
